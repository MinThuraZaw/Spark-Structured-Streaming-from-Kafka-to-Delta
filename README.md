### About
This repo demonstrates processing streaming data sources such as AWS Kinesis or Kafka in Databricks with Spark's Structured Streaming. Store the data in delta table and share it with others with Delta Sharing provided by Databricks.

<br>

### Pipeline
![alt text](https://github.com/MinThuraZaw/Spark-Structured-Streaming-in-Databricks/blob/main/images/structured_streaming.jpg)

<br>

### Requirements
1) Kinesis Source
2) Kafka Source
3) Databricks (single-user cluster for streaming source)
4) Delta Sharing (open-sharing for PowerBI)


**Languages**
* PySpark
* Databricks SQL


<br>

### Development Steps
1) 
(To be continue)
